{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dsptlp/prostate-mri?scriptVersionId=162805299\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pydicom as dicom\nimport os\nimport cv2\nimport pandas as pd\nimport math\nimport numpy as np\nimport glob\nfrom pathlib import Path\nfrom shutil import copyfile\nfrom shutil import copy\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 1 - CONVERT DICOM TO JPG","metadata":{}},{"cell_type":"code","source":"# Config Create Images\nimages_to_use = 25\nx_crop = 56\ny_crop = 56\nfolder_path = \"/kaggle/input/prostate-mri-us-biopsy/prostate_mri_us_biopsy/Prostate-MRI-US-Biopsy\"\noutput_folder_path = \"/kaggle/working\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_folder(folder_path):\n    \n    \"\"\"\n    process_folder processes DCOM images in the folder\n    \n    :param folder_path: folder to process\n    :return: jpg_list,dcm_values\n    \"\"\" \n    \n    jpg_list = []\n    dcm_values = []\n    \n    images_path = os.listdir(folder_path)\n\n    for image in images_path:\n        full_path = os.path.join(folder_path, image)\n        if image.endswith(\".dcm\"):\n            ds = dicom.dcmread(full_path)\n        \n            jpg_image_name = output_folder_path+full_path+\".jpg\"\n            jpg_list.append(jpg_image_name)\n                       \n            if not os.path.exists(output_folder_path+folder_path):\n                os.makedirs(output_folder_path+folder_path)\n            \n            cv2.imwrite(jpg_image_name, ds.pixel_array)\n                               \n            patient_name=''\n            patient_age=''\n            patient_size=''\n            patient_weight=''\n            patient_eth=''\n            patient_occ=''\n            patient_smoke=''\n            \n            try:\n                patient_name = ds[0x0010,0x0010].value\n            except:\n                pass\n            \n            try:\n                patient_age = ds[0x0010,0x1010].value\n            except:\n                pass\n            \n            try:\n                patient_size = ds[0x0010,0x1020].value\n            except:\n                pass\n\n            try:\n                patient_weight = ds[0x0010,0x1030].value\n            except:\n                pass\n            \n            try:\n                patient_eth = ds[0x0010,0x2160].value\n            except:\n                pass            \n            \n            try:\n                patient_occ = ds[0x0010,0x2180].value\n            except:\n                pass            \n            \n            try:\n                patient_smoke = ds[0x0010,0x21a0].value\n            except:\n                pass  \n            \n            dcm_values.append([patient_name,patient_age,patient_size,patient_weight,patient_eth,patient_occ,patient_smoke])\n            \n    return jpg_list,dcm_values,(output_folder_path+folder_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image(folder_path,x_crop,y_crop):\n    \n    \"\"\"\n    crop_image crops the image\n    \n    :param folder_path: folder to process\n    :param x_crop: pixel crop x\n    :param y_crop: pixel crop y\n    \"\"\" \n    \n    fileList = glob.glob(folder_path + '*jpg*')\n    \n    # Iterate over images\n    for filePath in fileList:\n        img = cv2.imread(filePath)\n        image_shape_x = img.shape[0]\n        image_shape_y = img.shape[1]\n                        \n        crop_img = img[(0+y_crop):(image_shape_y-y_crop), (0+x_crop):(image_shape_x-x_crop)]\n        cv2.imwrite(filePath, crop_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_jpg(folder_path):\n  \n    \"\"\"\n    remove_jpg removes jpg from folder\n    \n    :param folder_path: folder to process\n    \"\"\" \n    \n    # ==========================================================================================\n    # Remove old Final Files\n    # ==========================================================================================\n    fileList1  = glob.glob(folder_path + '**/*AX_T2*/*jpg*' , recursive=True)\n    fileList2 = glob.glob(folder_path + '**/*PROPELLER*/*jpg*' , recursive=True)\n    fileList3 = glob.glob(folder_path + '**/*axial*/*jpg*' , recursive=True)\n    fileList4 = glob.glob(folder_path + '**/*T2 Ax*/*jpg*' , recursive=True)\n    fileList5 = glob.glob(folder_path + '**/*AX T2*/*jpg*' , recursive=True)\n    fileList6 = glob.glob(folder_path + '**/*AX */*jpg*' , recursive=True)\n    fileList7 = glob.glob(folder_path + '**/*T2 AX*/*jpg*' , recursive=True)\n    fileList8 = glob.glob(folder_path + '**/*T2 SPACE*/*jpg*' , recursive=True)\n    fileList = fileList1 + fileList2 + fileList3 + fileList4 + fileList5 + fileList6 + fileList7 + fileList8  \n        \n    # Iterate over the list of filepaths & remove each file.\n    for filePath in fileList:    \n        try:            \n            os.remove(filePath)\n        except:\n            pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_patient_image(folder_path,images_to_use):\n    \n    \"\"\"\n    make_patient_image creates images\n    \n    :param folder_path: folder to process\n    :param images_to_use: images to use\n    \"\"\" \n               \n    # ==========================================================================================\n    # List all Images\n    # ==========================================================================================\n    images_path = os.listdir(folder_path)\n    image_list = []\n        \n    for image in images_path:\n        full_path = os.path.join(folder_path, image)\n        if image.endswith(\".jpg\"):\n            image_list.append(full_path)            \n    \n    #sort images\n    image_list.sort()\n    \n    image_cnt = len(image_list)\n    \n    image_ignore = math.floor((image_cnt- images_to_use)/2)\n            \n    #remove first x images\n    image_list = image_list[image_ignore:]\n    \n    #remove last x images\n    image_list = image_list[:len(image_list)-image_ignore]\n    \n    image_list = image_list[:images_to_use]\n            \n    image_cnt = len(image_list)\n    \n    if image_cnt == 25:\n        dims = 5\n    elif image_cnt == 16:\n        dims = 4\n    elif image_cnt == 4:\n        dims = 2\n    elif image_cnt < 4:\n        dims = 1        \n    else:\n        dims = math.ceil((math.sqrt(image_cnt)))   \n                              \n    # ==========================================================================================\n    # Looping Over Images to Concatenate and create Vertical\n    # ==========================================================================================\n    for coll_cnt in range(0,dims):\n\n        final_image = os.path.join(folder_path, \"finalV\" + str(coll_cnt)+\".jpg\")\n        zero_flag = 0\n        \n        #print(\"======================================\")\n        \n        for x in range(1,(dims)):        \n\n            image_number = (x - 1) + (coll_cnt * dims)\n\n            if image_number >= (image_cnt-1):\n                # set image file names\n                img1 = final_image\n                img2 = image_list[(0)]\n\n            elif zero_flag == 0:\n                # set image file names\n                img1 = image_list[image_number]\n                img2 = image_list[(image_number+1)]            \n                zero_flag = 1\n            else:\n                # set image file names\n                img1 = final_image\n                img2 = image_list[(image_number+1)]\n                \n            # read the images           \n            img1 = cv2.imread(img1)\n            img2 = cv2.imread(img2)\n            \n            try:\n                im_v = cv2.vconcat([img1, img2])   \n                cv2.imwrite(final_image, im_v)        \n            except:\n                pass\n                        \n    # ==========================================================================================\n    # Looping Over finalV images to concatenate into final image\n    # ==========================================================================================    \n    \n    final_image = os.path.join(folder_path, \"final.jpg\")\n    image_list = glob.glob(folder_path + '*final*')\n    image_cnt = len(image_list) - 1\n    zero_flag = 0\n    image_list.sort()\n        \n    for x in range(0,image_cnt):\n\n        if zero_flag == 0:\n            # set image file names\n            img1 = image_list[x]\n            img2 = image_list[(x+1)]            \n            zero_flag = 1\n        else:\n            # set image file names\n            img1 = final_image\n            img2 = image_list[(x+1)]\n            \n        # read the images\n        img1 = cv2.imread(img1)\n        img2 = cv2.imread(img2)\n\n        im_v = cv2.hconcat([img1, img2])   \n        cv2.imwrite(final_image, im_v)     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fileList = glob.glob(folder_path + '*/*0001*/*/*obl*' , recursive=True)\nfileList = glob.glob(folder_path + '*/*/*/*obl*' , recursive=True)\ndcm_metadata = []\n\nprint(len(fileList))\ncounter = 0\n\n# Remove all JPG\nremove_jpg(output_folder_path)\n\n# Sort List\nfileList.sort()\n\nfor folder in tqdm(fileList,desc = 'Progress Bar: Processing'  ):\n            \n    # Convert dicom to JPEG\n    jpg_list, dcm_values, output_folder = process_folder(folder+\"/\")\n    \n    # Append Metadata to FinalList\n    dcm_metadata.append(dcm_values)\n    \n    # Crop Image\n    crop_image(output_folder+\"/\",x_crop,y_crop)\n    \n    # Make collage\n    make_patient_image(output_folder+\"/\",images_to_use)\n    \n    counter = counter + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Empty DataFrame\ndf = pd.DataFrame(columns=['name','age','size','weight','ethnic_grp','occupation','smoking_status'])\n\n# Get Patient List\ncounter = 0\nfor entry in dcm_metadata:\n    df.loc[counter] = [entry[0][0]] + [entry[0][1]] + [entry[0][2]] + [entry[0][3]] + [entry[0][4]] + [entry[0][5]] + [entry[0][6]]\n    counter = counter + 1\n\ndf.to_csv(\"patients.csv\", sep=',', encoding='utf-8', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 2 CREATE POS/NEG DATASET","metadata":{}},{"cell_type":"code","source":"# Config Create Dataset\n# Destinations Folders\npso_folder = \"/kaggle/working/dataset/src/pos\"\nneg_folder = \"/kaggle/working/dataset/src/neg\"\n\n#Target Flags\nlabels_file = \"/kaggle/input/prostate-mri-us-biopsy/TCIA Biopsy Data_2020-07-14.xlsx\"\n\n#Source Images Path\nfolder_path = \"/kaggle/working/kaggle/input/prostate-mri-us-biopsy/prostate_mri_us_biopsy/Prostate-MRI-US-Biopsy\"\nfile_name = \"final.jpg\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(pso_folder):\n    os.makedirs(pso_folder)\n\nif not os.path.exists(neg_folder):\n    os.makedirs(neg_folder)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(patient_id):\n    df = labels_df[labels_df['Patient Number'].str.contains(patient_id)]\n    \n    df = df[df[\"% Cancer in Core\"] > 0]\n    \n    if len(df) > 0:\n        return 1\n    else:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def move_image(file_name,image,patient_id,scan_date):    \n    new_image_name = file_name +\"_\"+ scan_date +\"_\"+ patient_id +\".jpg\"\n    \n    if get_labels(patient_id) == 1:\n        dst_folder = pso_folder\n    else:\n        dst_folder = neg_folder\n    \n    final_image = os.path.join(dst_folder, new_image_name)\n            \n    copyfile(image, final_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==========================================================================================\n# Remove old Final Files\n# ==========================================================================================\nfileList = glob.glob(pso_folder+\"/\" + '*jpg*')\n\n# Iterate over the list of filepaths & remove each file.\nfor filePath in fileList:\n    try:\n        os.remove(filePath)\n    except:\n        print(\"Error while deleting file : \", filePath)\n\nfileList = glob.glob(neg_folder+\"/\" + '*jpg*')\n\n# Iterate over the list of filepaths & remove each file.\nfor filePath in fileList:\n    try:\n        os.remove(filePath)\n    except:\n        print(\"Error while deleting file : \", filePath)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df = pd.read_excel (labels_file)\nfileList = glob.glob(folder_path + '**/*/*/*/'+file_name   , recursive=True)\n#print(fileList[0:2])\n\nfor image in tqdm(fileList,desc = 'Progress Bar: Processing'  ):\n\n    patient_id = image[121:125]\n    scan_date = image[126:136]\n    \n#    print(image)\n#    print(patient_id)\n#    print(scan_date)\n    \n    move_image(file_name,image,patient_id,scan_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fileList = glob.glob(pso_folder + '**/*'  , recursive=True)\nprint(len(fileList))\n\n\nfileList = glob.glob(neg_folder + '**/*'  , recursive=True)\nprint(len(fileList))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 3 - TEST/TRAIN SPLIT","metadata":{}},{"cell_type":"code","source":"test_size = 0.4\nval_size = 0.5\nseed = 0\n\n#Train\ntrain_pos = \"/kaggle/working/dataset/ds1/train/pos/\"\ntrain_neg = \"/kaggle/working/dataset/ds1/train/neg/\"\n\n#Test\ntest_pos =  \"/kaggle/working/dataset/ds1/test/pos/\"\ntest_neg =  \"/kaggle/working/dataset/ds1/test/neg/\"\n\n#Val\nval_neg = \"/kaggle/working/dataset/ds1/val/neg/\"\nval_pos = \"/kaggle/working/dataset/ds1/val/pos/\"\n\n#File Prefix\nfile_prefix = 'final'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(train_pos):\n    os.makedirs(train_pos)\n\nif not os.path.exists(train_neg):\n    os.makedirs(train_neg)    \n    \nif not os.path.exists(test_pos):\n    os.makedirs(test_pos)    \n\nif not os.path.exists(test_neg):\n    os.makedirs(test_neg)    \n\nif not os.path.exists(val_neg):\n    os.makedirs(val_neg)    \n\nif not os.path.exists(val_pos):\n    os.makedirs(val_pos)    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_folder(folder,file_prefix):\n    \n    \"\"\"\n    clean_folder removes files with file_prefix\n    \n    :param folder_path: folder to process\n    :param file_prefix: file prefix\n    \"\"\" \n    \n    fileList = glob.glob(folder + '*'+ file_prefix + '*')\n    for filePath in fileList:\n        try:\n            os.remove(filePath)\n        except:\n            print(\"Error while deleting file : \", filePath)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_train(f1,f2,f3,f4,seed,file_prefix,file_loc_list):\n    \n    \"\"\"\n    make_test_train processes DCOM images in the folder\n    \n    :param f1: folder to process\n    :param f2: folder to process\n    :param f3: folder to process\n    :param f4: folder to process\n    :param seed: random seed\n    :param file_prefix: file prefix\n    :param file_loc_list: file location list\n    :return: file_loc_list\n    \"\"\" \n        \n    fileList = glob.glob(f3 + '**/*' + file_prefix +'*' , recursive=True)\n    data = np.array(fileList)\n    x_train ,x_test = train_test_split(data,test_size=test_size,random_state=seed)\n    \n    x_test,x_val    = train_test_split(x_test,test_size=val_size,random_state=seed)\n\n    for file in x_train:\n        file_loc_list.append([\"train\",file])\n        copy(str(file), f1)\n\n    for file in x_test:\n        file_loc_list.append([\"test\",file])\n        copy(str(file), f2)\n        \n    for file in x_val:\n        file_loc_list.append([\"val\",file])\n        copy(str(file), f4)\n        \n    return file_loc_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_folder(train_pos,file_prefix)\nclean_folder(test_pos,file_prefix)\nclean_folder(val_pos,file_prefix)\n\nclean_folder(train_neg,file_prefix)\nclean_folder(test_neg,file_prefix)\nclean_folder(val_neg,file_prefix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_loc_list = []\n\nfile_loc_list = make_test_train(train_pos,test_pos,pso_folder,val_pos,seed,file_prefix,file_loc_list)\nfile_loc_list = make_test_train(train_neg,test_neg,neg_folder,val_neg,seed,file_prefix,file_loc_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_loc_list\n\n# Create Empty DataFrame\ndf = pd.DataFrame(columns=['s1','s2','s3'])\ncounter = 0\nfor entry in file_loc_list:    \n    df.loc[counter] = [entry[0]] + [entry[1]] + [entry[1][42:46]]\n    counter = counter + 1\n    \ndf.to_csv(\"train_test_val.csv\", sep=',', encoding='utf-8', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 4 - TRAIN DNN MODEL","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 2\nSTART_EPOCH = 0\nwb_project = \"DNN-Model\"\nEPOCHS = 400\nLR = 0.01\nMOMENTUM = 0.9\nWEIGHT_DECAY = 0.5\nPRINT_FREQ = 50\nTRAIN_BATCH = 21\nimagesize = 700\nWORKERS = 4\nLR_EPOCH_DROP = 80\nARCH = \"resnet50\"\ncosine_hoops = 2\nTRAINDIR = \"/kaggle/working/dataset/ds1/train/\"\nVALDIR = \"/kaggle/working/dataset/ds1/val/\"\nmodel_save_file = \"model_MRI.pth.tar\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport shutil\nimport time\nimport pandas as pd\nimport numpy as np\nimport math\nimport json\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom datetime import timedelta\nimport datetime\nimport torch.distributed as dist\n\n\nfrom torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport torch.nn.functional as F\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torch import optim\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nfrom timm.scheduler.cosine_lr import CosineLRScheduler\nfrom timm.scheduler.step_lr import StepLRScheduler","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GPU=0\n\nSEED=1\nVAL_BATCH=TRAIN_BATCH\n\n\nclasses_train = os.listdir(TRAINDIR)\nclasses_valid = os.listdir(VALDIR)\n\nprint(classes_train)\nprint(classes_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_folder in classes_train:\n    print(\"==================================\")\n    class_folder = class_folder +'/'\n    full_path = os.path.join(TRAINDIR, class_folder)\n    print(full_path)\n    fileList = glob.glob(full_path +'*jpg*', recursive=True)\n    print(len(fileList))\n\nfor class_folder in classes_valid:\n    print(\"==================================\")\n    class_folder = class_folder +'/'\n    full_path = os.path.join(VALDIR, class_folder)\n    print(full_path)\n    fileList = glob.glob(full_path +'*jpg*', recursive=True)\n    print(len(fileList))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter('Time', ':6.3f')\n    data_time = AverageMeter('Data', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    top5 = AverageMeter('Acc@5', ':6.2f')\n    progress = ProgressMeter(\n        len(train_loader),\n        [batch_time, data_time, losses, top1, top5],\n        prefix=\"Epoch: [{}]\".format(epoch))\n\n    # Grad Scaler\n    scaler = GradScaler()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (images, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if GPU is not None:\n            images = images.cuda(GPU, non_blocking=True)\n        if torch.cuda.is_available():\n            target = target.cuda(GPU, non_blocking=True)\n\n        # compute output\n        with autocast():\n          output = model(images)\n          loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        acc1, acc5 = accuracy(output, target, topk=(1, 2))\n        losses.update(loss.item(), images.size(0))\n        top1.update(acc1[0], images.size(0))\n        top5.update(acc5[0], images.size(0))\n        \n        # use the scaler\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % PRINT_FREQ == 0:\n            progress.display(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader, model, criterion):\n    batch_time = AverageMeter('Time', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    top5 = AverageMeter('Acc@5', ':6.2f')\n    progress = ProgressMeter(\n        len(val_loader),\n        [batch_time, losses, top1, top5],\n        prefix='Test: ')\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (images, target) in enumerate(val_loader):\n            if GPU is not None:\n                images = images.cuda(GPU, non_blocking=True)\n            if torch.cuda.is_available():\n                target = target.cuda(GPU, non_blocking=True)\n\n            # compute output\n            output = model(images)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            acc1, acc5 = accuracy(output, target, topk=(1, 2))\n            losses.update(loss.item(), images.size(0))\n            top1.update(acc1[0], images.size(0))\n            top5.update(acc5[0], images.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % PRINT_FREQ == 0:\n                progress.display(i)\n\n        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(state, is_best, filename_in):\n    #torch.save(state, filename_in)\n    if is_best:\n        #shutil.copyfile(filename_in, 'model_best.pth.tar')\n        torch.save(state, 'model_best.pth.tar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n    lr = LR * (0.1 ** (epoch // LR_EPOCH_DROP))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(SEED)\ntorch.manual_seed(SEED)\ncudnn.deterministic = False\ncudnn.benchmark = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize((imagesize,imagesize)),\n    transforms.RandomAffine(degrees=3),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(degrees=(0, 5)),\n    #transforms.RandomPerspective(distortion_scale=0.8, p=1.0),\n    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.9, 0.99)),\n    #transforms.RandomEqualize(),\n    #transforms.RandomAutocontrast(),\n    #transforms.RandomSolarize(threshold=192.0),\n    #transforms.RandomPosterize(bits=2),\n    #transforms.RandomInvert(),\n    #transforms.RandomAdjustSharpness(sharpness_factor=2),\n    #transforms.Resize(imagesize),\n    transforms.ToTensor(),\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((imagesize,imagesize)),\n    transforms.ToTensor(),    \n])\n\ntrain_dataset = datasets.ImageFolder(TRAINDIR, transform=transform_train)\nval_dataset = datasets.ImageFolder(VALDIR, transform=transform_val)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH, shuffle=True,num_workers=WORKERS, pin_memory=True, sampler=None)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=VAL_BATCH, shuffle=False,num_workers=WORKERS, pin_memory=True, sampler=None)\n\nprint(train_loader.dataset.classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not torch.cuda.is_available():\n    print('GPU not detected.. did you pass through your GPU?')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 2\n\n# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device\",str(device))\n\nmodel = timm.create_model(ARCH, pretrained = True, num_classes=NUM_CLASSES)\nmodel = model.to(device)\n\n# Loss function\ncriterion = torch.nn.CrossEntropyLoss()\n\n# Scheduler and Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = timm.scheduler.StepLRScheduler(optimizer, decay_t = LR_EPOCH_DROP, decay_rate=WEIGHT_DECAY)\n\nn_steps = len(train_loader.dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nbest_acc1 = 0\nbest_epoch = 0\nlrls = []\nfor epoch in range(START_EPOCH, EPOCHS):\n\n    # train for one epoch\n    train(train_loader, model, criterion, optimizer, epoch)\n\n    # evaluate on validation set\n    acc1 = validate(val_loader, model, criterion)\n\n    # remember best acc@1 and save checkpoint\n    is_best = acc1 > best_acc1\n    best_acc1 = max(acc1, best_acc1)\n\n    PATH = \"M1_\" +str(epoch) + \"_acc1_\" +str(acc1) + \"_\" + ARCH + \".tar\" \n    save_checkpoint({\n        'epoch': epoch + 1,\n        'arch': ARCH,\n        'state_dict': model.state_dict(),\n        'best_acc1': best_acc1,\n        'optimizer' : optimizer.state_dict(),\n    }, is_best,PATH)\n    \n    scheduler.step(epoch + 1)\n    lr_rate =  get_lr(optimizer)\n    lrls.append(lr_rate)          \n    print('lr: ' + str(lr_rate))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = pd.Series(lrls).plot(logy=True, figsize = (15, 6), title=\"Learning Rate VS Epoch\")\nfor i in range(0,EPOCHS,1): \n    ax.axvline(i, linewidth=0.01, color='r', linestyle='--')\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"LR (log scale)\")\nfig = ax.get_figure()\nfig.savefig('LR_graph-log.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(4, 2),frameon =False, dpi=200)  \nplt.title('Learning Rate VS Epoch')\nplt.plot(lrls)\nplt.ylabel('Learning Rate')\nplt.xlabel('Epoch')\nfn = \"LR_graph.png\"\nplt.savefig(fn,bbox_inches='tight')\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RESULTS","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntest_transforms = transform_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(image):\n    \n    model.eval()\n    with torch.no_grad():\n    \n        image_tensor = test_transforms(image).float()\n        image_tensor = image_tensor.unsqueeze_(0)\n        input = Variable(image_tensor)\n        input = input.to(device)\n        output = model(input)\n        index = output.data.cpu().numpy().argmax()\n       \n    return index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_images(num):\n    data = datasets.ImageFolder(VALDIR, transform=test_transforms)\n    classes = data.classes\n    indices = list(range(len(data)))\n    np.random.shuffle(indices)\n    idx = indices[:num]\n    sampler = SubsetRandomSampler(idx)\n    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n    images, labels = next(iter(loader))  # Get the first batch of data   \n    return images, labels, classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_pil = transforms.ToPILImage()\nimages, labels, classes = get_random_images(15)\nfig=plt.figure(figsize=(15,15))\n\ncounter = 0\nwhile counter < 5:\n    to_pil = transforms.ToPILImage()\n    images, labels, classes = get_random_images(10)\n    fig=plt.figure(figsize=(17,17))\n    for ii in range(len(images)):\n        image = to_pil(images[ii])\n        index = predict_image(image)\n        sub = fig.add_subplot(1, len(images), ii+1)\n        res = int(labels[ii])\n        label_class = int(labels[ii])\n        sub.set_title(str(classes[index]) + \":\" + classes[label_class])\n        plt.axis('off')\n        plt.imshow(image)\n    plt.show()\n    counter = counter + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"actual = []\npredicted = []\n\nto_pil = transforms.ToPILImage()\nimages, labels, classes = get_random_images(3000)\nfor ii in range(len(images)):\n    image = to_pil(images[ii])\n    index = predict_image(image)\n    res = int(labels[ii])\n    label_class = int(labels[ii])\n    actual.append(classes[label_class])\n    predicted.append(str(classes[index]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(actual[20])\nprint(predicted[20])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(actual, predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig = plt.figure(figsize=(4, 4),frameon =False, dpi=200)  \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.1f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools  # Add this line to import itertools\n\n# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = classes\nplot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\nplt.show()\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')\nplt.show()\n\nprint(classification_report(actual, predicted, target_names=class_names))\n\nprint(accuracy_score(actual, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_ROC_graph(labels_test,prediction):\n    \"\"\" Text \"\"\"\n\n    false_positive_rate, recall, thresholds = roc_curve(labels_test,prediction)\n    roc_auc = auc(false_positive_rate, recall)\n    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' %roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    fn = \"roc_graph.png\"\n    plt.savefig(fn,bbox_inches='tight')\n    plt.show()\n    plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual_b = []\npredicted_b = []\n\nfor x in actual:\n    if x == 'pos':\n        actual_b.append(1)\n    else:\n        actual_b.append(0)\n\nfor x in predicted:\n    if x == 'pos':\n        predicted_b.append(1)\n    else:\n        predicted_b.append(0)\n                \nmake_ROC_graph(actual_b,predicted_b)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import required libraries/code\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport shutil\nimport os\nimport requests\nimport zipfile\nimport torch.backends.cudnn as cudnn\nimport pandas as pd\n\nfrom pathlib import Path\n\nfrom torch import nn\nfrom torchvision import transforms, datasets\n\n# Try to get torchinfo, install it if it doesn't work\ntry:\n    from torchinfo import summary\nexcept:\n    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n    !pip install -q torchinfo\n    from torchinfo import summary\n\n# See if torchmetrics exists, if not, install it\ntry:\n    import torchmetrics, mlxtend\n    print(f\"mlxtend version: {mlxtend.__version__}\")\n    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\nexcept:\n    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n    import torchmetrics, mlxtend\n    print(f\"mlxtend version: {mlxtend.__version__}\")\n    \n# Import mlxtend upgraded version\nimport mlxtend \nprint(mlxtend.__version__)\nassert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher\n\nfrom torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom pathlib import Path\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\nimport numpy as np\nfrom sklearn import metrics\nimport torchvision\nimport matplotlib.pyplot as plt\n\nimport torch\n\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ntry:\n    import wandb\nexcept:\n    !pip install wandb boto3\n    !pip install ipywidgets\n    !apt-get update\n    !apt-get install htop\n    import wandb\n    import boto3\n\nimport wandb    \nimport boto3\nfrom botocore.exceptions import NoCredentialsError\nimport json\nimport random\n\ntry:\n    import timm\nexcept:\n    !pip install timm\n    import timm\n    \nfrom timm.scheduler.cosine_lr import CosineLRScheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import lr_scheduler\n\nfrom timm.scheduler.step_lr import StepLRScheduler\n\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AWS_ACCESS_KEY = 'x'\nAWS_SECRET_KEY = 'x'\nregion_name = 'us-east-1'\nWANDB_API_KEY = 'x'\nphone = 'x'\n\ndebug = False\n\nSEED=1\nARCH = 'efficientnet_b5'\n\nDROPOUT=0.2\nEPOCHS = 30\nLR = 0.01\ndecay_t = 5\nMOMENTUM = 0.9\nWEIGHT_DECAY = 1e-4\nNUM_CLASSES = 2\nTRAIN_BATCH = 7\nVAL_BATCH=TRAIN_BATCH\nNUM_WORKERS = os.cpu_count()\nwb_project = \"RSNA\"\nmodel_save_file = \"model_DNN.pth.tar\"\ns3_bucket = 'pparkitnrsna'\nScheduler_name = 'ReduceLROnPlateau' # 'CosineAnnealingLR' 'StepLR' 'ReduceLROnPlateau' 'MultiStepLR'\nuse_autocast = True\nfreeze_all_layers = True\n\n# LOAD SAVED MODEL\nLoadModel = False\nLoadModelName = '/kaggle/input/rsna-wheel/model_best_playful-cloud-263.pth.tar'\nif LoadModel == False:\n    LoadModelName = \"N/A\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL PARAMETERS","metadata":{}},{"cell_type":"code","source":"# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\n\nif ARCH == 'efficientnet_b7':\n    imagesize = 600\n    in_features=2560\n    model_0 = torchvision.models.efficientnet_b7(pretrained=True,num_clases = NUM_CLASSES,weights='DEFAULT',in_chans=3).to(device)\n\nelif ARCH == 'efficientnet_b5':\n    imagesize = 448\n    in_features=2048\n    model_0 = torchvision.models.efficientnet_b5(pretrained=True,num_clases = NUM_CLASSES,weights='DEFAULT',in_chans=3).to(device)\n\nelif ARCH == 'efficientnet_b2':\n    imagesize   = 256\n    in_features = 1408\n    model_0 = torchvision.models.efficientnet_b2(pretrained=True,num_clases = NUM_CLASSES,weights='DEFAULT',in_chans=3).to(device)\n\nelif ARCH == 'efficientnet_b0':\n    imagesize   = 244\n    in_features =1280\n    model_0 = torchvision.models.efficientnet_b0(pretrained=True,num_clases = 1,weights='DEFAULT',in_chans=3).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SETUP W&B","metadata":{}},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n\nwandb.login()\nrun  = wandb.init(project=wb_project, entity='pparkitny', config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \n                   \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH, \"imagesize\":imagesize, \"NUM_CLASSES\":NUM_CLASSES})\n\nwandb_run_name = wandb.run.name\nwandb_run_id = wandb.run.id\n\nconfig = wandb.config\nconfig.learning_rate = LR\nconfig.Scheduler_name = Scheduler_name\nconfig.LoadModel = LoadModel\nconfig.LoadModelName = LoadModelName\nconfig.decay_t = decay_t\nconfig.use_autocast = use_autocast\nconfig.DROPOUT = DROPOUT\nconfig.debug=debug\nconfig.freeze_all_layers = freeze_all_layers\n\nwandb.run.log_code(\".\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get data ","metadata":{"id":"nrzg3TaSKLAh"}},{"cell_type":"code","source":"# Setup path to data folder\ndata_path = Path(\"data/\")\nimage_path = data_path / \"pizza_steak_sushi\"\n\n# If the image folder doesn't exist, download it and prepare it... \nif image_path.is_dir():\n    print(f\"{image_path} directory exists.\")\nelse:\n    print(f\"Did not find {image_path} directory, creating one...\")\n    image_path.mkdir(parents=True, exist_ok=True)\n    \n    # Download pizza, steak, sushi data\n    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n        print(\"Downloading pizza, steak, sushi data...\")\n        f.write(request.content)\n\n    # Unzip pizza, steak, sushi data\n    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n        print(\"Unzipping pizza, steak, sushi data...\") \n        zip_ref.extractall(image_path)\n\n    # Remove .zip file\n    os.remove(data_path / \"pizza_steak_sushi.zip\")\n\n# Setup Dirs\ntrain_dir = image_path / \"train\"\ntest_dir = image_path / \"test\"","metadata":{"id":"Lt_CNQ4rKPmg","outputId":"a1364d91-3afa-4401-94cb-94e4df837f06","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm data/pizza_steak_sushi/test/pizza/ -R\n!rm data/pizza_steak_sushi/train/pizza/ -R","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug == False:       \n    train_dir = '/kaggle/input/rsna-1024-tt-dup-a/train/tmp/working/data/1024/train'\n    test_dir = '/kaggle/input/rsna-1024-tt-dup-a/test/tmp/working/data/1024/test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare data","metadata":{"id":"PGaMWWaoKQlM"}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((imagesize, imagesize)), \n    #transforms.RandomAffine(degrees=3),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomRotation(degrees=(-5, 5)),    \n    #transforms.RandomPerspective(distortion_scale=0.8, p=1.0),\n    #transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.3), scale=(0.9, 0.99)),    \n    #transforms.RandomEqualize(),\n    #transforms.RandomAutocontrast(),\n    #transforms.RandomSolarize(threshold=192.0),\n    #transforms.RandomPosterize(bits=2),\n    #transforms.RandomInvert(),\n    #transforms.RandomAdjustSharpness(sharpness_factor=2),\n    transforms.Grayscale(num_output_channels=3), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((imagesize, imagesize)), \n    transforms.Grayscale(num_output_channels=3), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n])\n\ntrain_data = datasets.ImageFolder(train_dir, transform=train_transform)\ntest_data = datasets.ImageFolder(test_dir, transform=test_transform)\n\nclass_names = train_data.classes\n\ntrain_dataloader = DataLoader(\n      train_data,\n      batch_size=TRAIN_BATCH,\n      shuffle=True,\n      num_workers=NUM_WORKERS,\n      pin_memory=True,\n  )\n\ntest_dataloader = DataLoader(\n      test_data,\n      batch_size=TRAIN_BATCH,\n      shuffle=False,\n      num_workers=NUM_WORKERS,\n      pin_memory=True,\n  )\n\nprint(len(train_dataloader.dataset))\nprint(class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PF1 Score","metadata":{}},{"cell_type":"code","source":"def pfbeta(labels, predictions, beta):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get and prepare a pretrained model","metadata":{"id":"Ciw2DiRHKaSE"}},{"cell_type":"code","source":"if freeze_all_layers == True:\n\n    # Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n    for param in model_0.features.parameters():\n        param.requires_grad = False\n        \nif 1==2:\n    ct = 0\n    for child in model.children():\n        ct += 1\n        if ct < 4:\n            for param in child.parameters():\n                param.requires_grad = False","metadata":{"id":"IbRhGvy_KeVL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model=model_0, input_size=(TRAIN_BATCH, 3, imagesize, imagesize),col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"],\n        verbose=2,\n        depth=1\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the manual seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# Get the length of class_names (one output unit for each class)\noutput_shape = len(class_names)\n\n# Recreate the classifier layer and seed it to the target device\nmodel_0.classifier = torch.nn.Sequential(\n    torch.nn.Dropout(p=DROPOUT, inplace=True), \n    torch.nn.Linear(in_features=in_features,\n                    out_features=output_shape, \n                    bias=True)).to(device)\n","metadata":{"id":"G1-6xV3ZKeSX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD SAVED MODEL","metadata":{}},{"cell_type":"code","source":"if LoadModel == True:\n    print(\"Loading Model\",LoadModelName)\n    \n    # Setup device agnostic code\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    device\n\n    if torch.cuda.is_available() == True:\n        loc = 'cuda:{}'.format('0')\n        model_0 = torch.load(LoadModelName)\n        cudnn.deterministic = True\n        cudnn.benchmark = True\n    else:\n        loc=torch.device('cpu') \n        model_0 = torch.load(LoadModelName,map_location=torch.device('cpu'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train model","metadata":{"id":"XQFaXX8CKePi"}},{"cell_type":"code","source":"def upload_to_aws(local_file, bucket, s3_file):\n    s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY,\n                      aws_secret_access_key=AWS_SECRET_KEY)\n    try:\n        s3.upload_file(local_file, bucket, s3_file)\n        print(\"Upload Successful\")\n        return True\n    except FileNotFoundError:\n        print(\"The file was not found\")\n        return False\n    except NoCredentialsError:\n        print(\"Credentials not available\")\n        return False\n\ndef download_from_aws(s3_file, bucket):\n    s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY,\n                      aws_secret_access_key=AWS_SECRET_KEY)\n    try:\n        s3.download_file(bucket, s3_file, s3_file)\n        print(\"Download Successful\")\n        return True\n    except FileNotFoundError:\n        print(\"The file was not found\")\n        return False\n    except NoCredentialsError:\n        print(\"Credentials not available\")\n        return False\n    \ndef send_sms(phone,text,aws_access_key_id,aws_secret_access_key,region_name):\n    # Create an SNS client\n    client = boto3.client(\n        \"sns\",\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n        region_name=region_name\n    )\n\n    # Send sms message.\n    client.publish(\n        PhoneNumber=phone,\n        Message=text\n    )\n    \ndef list_files_from_aws(bucket):\n    fileList = []\n    s3 = boto3.resource('s3', aws_access_key_id=AWS_ACCESS_KEY,aws_secret_access_key=AWS_SECRET_KEY)\n    my_bucket = s3.Bucket(bucket)\n    for my_bucket_object in my_bucket.objects.all():\n        fileList.append(str(my_bucket_object.key))\n    return fileList\n\ndef filter_list(input_list,contains):\n    \n    list_return = []\n    \n    for item in input_list:\n        if item.find(contains) != -1:\n            list_return.append(item)\n    \n    return(list_return)\n\ndef remove_from_list(input_list,contains):\n    \n    list_return = []\n    \n    for item in input_list:\n        if item.find(contains) == -1:\n            list_return.append(item)\n    \n    return(list_return)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(state, is_best, filename_in,model):\n    torch.save(state, filename_in)\n    torch.save(model,'model'+filename_in)\n    \n    if is_best:\n        shutil.copyfile(filename_in, 'weights_best_'+wandb_run_name+'.pth.tar')\n        upload_to_aws('weights_best_'+wandb_run_name+'.pth.tar', s3_bucket, 'weights_best_'+wandb_run_name+'.pth.tar')\n        \n        shutil.copyfile('model'+filename_in, 'model_best_'+wandb_run_name+'.pth.tar')\n        upload_to_aws('model_best_'+wandb_run_name+'.pth.tar', s3_bucket, 'model_best_'+wandb_run_name+'.pth.tar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n        \n        #LOG WANDB\n        #wandb.log({\"Loss/train\": loss, 'acc1/train': train_acc })\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss, test_acc = 0, 0\n\n    # Turn on inference context manager\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            \n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    return test_loss, test_acc\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n\n    best_acc1 = 0\n    best_epoch = 0\n    \n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"test_loss\": [],\n               \"test_acc\": []\n    }\n    \n    # Make sure model on target device\n    model.to(device)\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        \n        lr_rate=get_lr(optimizer)\n        \n        train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n        test_loss, test_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n        # Print out what's happening\n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"LR: {lr_rate:.6f} | \"  \n          f\"train_loss: {train_loss:.6f} | \"\n          f\"train_acc: {train_acc:.6f} | \"\n          f\"test_loss: {test_loss:.6f} | \"\n          f\"test_acc: {test_acc:.6f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n        # remember best acc@1 and save checkpoint\n        is_best = test_acc > best_acc1\n        best_acc1 = max(test_acc, best_acc1)\n        \n        if is_best == True:\n            best_epoch = epoch\n                \n        PATH = str(epoch) + \"_\" +str(test_acc) + \"_\" + ARCH + \".tar\" \n        save_checkpoint({\n        'epoch': epoch,\n        'arch': ARCH,\n        'state_dict': model.state_dict(),\n        'best_acc1': best_acc1,\n        'optimizer' : optimizer.state_dict(),}, is_best,PATH,model)\n        \n        scheduler.step(epoch)\n                \n        wandb.log({'lr':lr_rate, \n                   'epoch':epoch,\n                   \"best_acc1/val\": best_acc1,\n                   \"best_epoch\": best_epoch,\n                  'train_loss':train_loss,\n                  'train_acc':train_acc,\n                  'test_loss':test_loss,\n                  'test_acc':test_acc})    \n        \n\n    # Return the filled results at the end of the epochs\n    return results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_0.parameters(), lr=LR)\nscheduler = timm.scheduler.StepLRScheduler(optimizer, decay_t = decay_t, decay_rate=.5)","metadata":{"id":"exxU79eaKeM6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Set the random seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\n# Start the timer\nfrom timeit import default_timer as timer \nstart_time = timer()\n\n# Setup training and save the results\nmodel_0_results = train(model=model_0,\n                       train_dataloader=train_dataloader,\n                       test_dataloader=test_dataloader,\n                       optimizer=optimizer,\n                       loss_fn=loss_fn,\n                       epochs=EPOCHS,\n                       device=device)\n\n# End the timer and print out how long it took\nend_time = timer()\nprint(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")","metadata":{"id":"ComVkVtuKeKG","outputId":"6d43205a-4e9f-4627-999a-40d07380cd58","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD BEST MODEL WEIGHTS","metadata":{}},{"cell_type":"code","source":"model_name = 'weights_best_'+wandb_run_name+'.pth.tar'\n\nif torch.cuda.is_available() == True:\n    loc = 'cuda:{}'.format('0')\nelse:\n    loc=torch.device('cpu') \n\ncheckpoint = torch.load(model_name, map_location=loc)\nprint(checkpoint['arch'])\nmodel_0.load_state_dict(checkpoint['state_dict'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = test_data.classes\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD BEST FULL MODEL","metadata":{}},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((imagesize, imagesize)), \n    transforms.Grayscale(num_output_channels=3), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n])\n\ntest_data = datasets.ImageFolder(test_dir, transform=test_transform)\n\ntest_dataloader = DataLoader(\n      test_data,\n      batch_size=TRAIN_BATCH,\n      shuffle=False,\n      num_workers=NUM_WORKERS,\n      pin_memory=True,\n  )\n\nclass_names = test_data.classes\nprint(\"class_names\",class_names)\n\nmodel_name = 'model_best_'+wandb_run_name+'.pth.tar'\n\n# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\nif torch.cuda.is_available() == True:\n    loc = 'cuda:{}'.format('0')\n    model_0 = torch.load(model_name)\nelse:\n    loc=torch.device('cpu') \n    model_0 = torch.load(model_name,map_location=torch.device('cpu'))\n    \n#put model in evaluation mode\nmodel_0.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make predictions on the entire test dataset with the model","metadata":{"id":"xFS4lE_IKyE_"}},{"cell_type":"code","source":"# Make predictions on the entire test dataset\ntest_preds = []\ntest_probs = []\nmodel_0.eval()\nwith torch.inference_mode():\n  # Loop through the batches in the test dataloader\n  for X, y in tqdm(test_dataloader):\n\n    X, y = X.to(device), y.to(device)\n    # Pass the data through the model\n    test_logits = model_0(X)\n\n    # Convert the pred logits to pred probs\n    pred_probs = torch.softmax(test_logits, dim=1)\n\n    # Convert the pred probs into pred labels\n    pred_labels = torch.argmax(pred_probs, dim=1)\n\n    # Add the pred labels to test preds list\n    test_preds.append(pred_labels)\n    test_probs.append(pred_probs)\n\n# Concatenate the test preds and put them on the CPU\ntest_preds = torch.cat(test_preds).cpu()\n\ntest_probs = torch.cat(test_probs).cpu()","metadata":{"id":"FFHEP24CK2Zm","outputId":"772668fd-bae8-4366-ce61-85adf7eafa6c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAKE ROC GRAPH","metadata":{}},{"cell_type":"code","source":"def make_ROC_graph(labels_test,prediction):\n    \"\"\" Text \"\"\"\n\n    false_positive_rate, recall, thresholds = roc_curve(labels_test,prediction)\n    roc_auc = auc(false_positive_rate, recall)\n    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' %roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    fn = \"roc_graph.png\"\n    plt.savefig(fn,bbox_inches='tight')\n    plt.show()\n    plt.close()\n    wandb.log({\"Media/ROC-Graph\": wandb.Image(\"roc_graph.png\")})\n    config.AUC = roc_auc\n    return roc_auc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PREDICTIONS","metadata":{"id":"YqlStPo-gbrF"}},{"cell_type":"code","source":"classes = class_names\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug == False:\n    test_data_paths = list(Path(test_dir).glob(\"*/*.png\"))\nelse:\n    test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\ntest_data_paths[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all test data paths\ntest_labels = [path.parent.stem for path in test_data_paths]\n\n# Create a function to return a list of dictionaries with sample, label, prediction, pred prob\ndef pred_and_store(test_paths, model, transform, class_names, device):\n  test_pred_list = []\n  for path in tqdm(test_paths):\n    # Create empty dict to store info for each sample\n    pred_dict = {}\n\n    # Get sample path\n    pred_dict[\"image_path\"] = path\n\n    # Get class name\n    class_name = path.parent.stem\n    pred_dict[\"class_name\"] = class_name\n\n    # Get prediction and prediction probability\n    from PIL import Image\n    img = Image.open(path) # open image\n    transformed_image = transform(img).unsqueeze(0) # transform image and add batch dimension\n    model.eval()\n    with torch.inference_mode():\n        pred_logit = model(transformed_image.to(device))\n        pred_prob = torch.softmax(pred_logit, dim=1)\n        pred_label = torch.argmax(pred_prob, dim=1)\n        pred_class = class_names[pred_label.cpu()]\n\n        # Make sure things in the dictionary are back on the CPU \n        pred_dict[\"pred_prob\"] = pred_prob.unsqueeze(0).max().cpu().item()\n        pred_dict[\"pred_class\"] = pred_class\n                        \n        pred_dict[\"pred_label_int\"] = classes.index(pred_class)\n        pred_dict[\"class_name_int\"] = classes.index(class_name)\n        \n  \n    # Does the pred match the true label?\n    pred_dict[\"correct\"] = class_name == pred_class\n\n    # print(pred_dict)\n    # Add the dictionary to the list of preds\n    test_pred_list.append(pred_dict)\n\n  return test_pred_list\n\ntest_pred_dicts = pred_and_store(test_paths=test_data_paths,\n                                 model=model_0,\n                                 transform=test_transform,\n                                 class_names=class_names,\n                                 device=device)\n\ntest_pred_dicts[:1]","metadata":{"id":"b7TY5_CegbQA","outputId":"5e114711-0315-4dbe-fd36-2c372ec3e5fe","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual_name = []\npred_class = []\npred_logit = []\npred_label = []\npred_label_int = []\nclass_name_int = []\n\nfor rec in test_pred_dicts:\n    actual_name.append(rec['class_name'])\n    class_name_int.append(rec['class_name_int'])\n    pred_class.append(rec['pred_class'])\n    pred_label_int.append(rec['pred_label_int'])\n    \nmake_ROC_graph(class_name_int,pred_label_int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig = plt.figure(figsize=(4, 4),frameon =False, dpi=200)  \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.1f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(actual_name, pred_class)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,title='Confusion matrix')\nplt.savefig(\"confusion-matrix.png\",bbox_inches='tight')\nplt.show()\nwandb.log({\"Media/Confusion Matrix\": wandb.Image(\"confusion-matrix.png\")})\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,title='Normalized confusion matrix')\nplt.savefig(\"confusion-matrix-normalized.png\",bbox_inches='tight')\nplt.show()\nwandb.log({\"Media/Normalized Confusion Matrix\": wandb.Image(\"confusion-matrix-normalized.png\")})\n\nprint(classification_report(actual_name, pred_class, target_names=classes))\nprint(accuracy_score(actual_name, pred_class))\n\nconfig.classification_report = classification_report(actual_name, pred_class, target_names=class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn the test_pred_dicts into a DataFrame\n\ntest_pred_df = pd.DataFrame(test_pred_dicts)\n\n# Sort DataFrame by correct then by pred_prob \ntop_5_most_wrong = test_pred_df.sort_values(by=[\"correct\", \"pred_prob\"], ascending=[True, False]).head()\ntop_5_most_wrong","metadata":{"id":"3LztXBXQO5KC","outputId":"661bc01e-4f4f-4216-edcb-7f36d4fa3ad1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the top 5 most wrong images\nfor row in top_5_most_wrong.iterrows():\n    row = row[1]\n    image_path = row[0]\n    true_label = row[1]\n    pred_prob = row[2]\n    pred_class = row[3]\n    # Plot the image and various details\n    img = torchvision.io.read_image(str(image_path)) # get image as tensor\n    plt.figure()\n    plt.imshow(img.permute(1, 2, 0)) # matplotlib likes images in [height, width, color_channels]\n    plt.title(f\"True: {true_label} | Pred: {pred_class} | Prob: {pred_prob:.3f}\")\n    plt.axis(False);","metadata":{"id":"SKLXlQh9ToOc","outputId":"f1ac55c4-f75c-4d57-fc95-95f36e0d3368","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a function to pred and plot images\ndef pred_and_plot(image_path, model, transform, class_names, device=device):\n  # open image\n  image = Image.open(image_path)\n\n  # transform image\n  transformed_image = transform(image)\n\n  # pred on image\n  model.eval()\n  with torch.inference_mode():\n    pred_logit = model(transformed_image.unsqueeze(0).to(device))\n    pred_label = torch.argmax(torch.softmax(pred_logit, dim=1), dim=1)\n  \n  # plot image and pred\n  plt.figure() \n  plt.imshow(image)\n  plt.title(f\"Pred: {class_names[pred_label]}\")\n  plt.axis(False);","metadata":{"id":"CwpjoyDsX1dw","outputId":"7e5599d0-591f-4133-97bb-47e7c6c1a494","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try again on a photo of steak from unsplash.com \n!wget https://images.unsplash.com/photo-1546964124-0cce460f38ef\n!cp photo-1546964124-0cce460f38ef steak.jpg\n\npred_and_plot(\"steak.jpg\",\n              model=model_0,\n              transform=test_transform,\n              class_names=class_names)","metadata":{"id":"_AIfSlZdaNpt","outputId":"83f98e26-4b31-4393-83ee-c5b3d57ae865","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot loss curves of a model\ndef plot_loss_curves(results):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n    loss = results[\"train_loss\"]\n    test_loss = results[\"test_loss\"]\n\n    accuracy = results[\"train_acc\"]\n    test_accuracy = results[\"test_acc\"]\n\n    epochs = range(len(results[\"train_loss\"]))\n\n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label=\"train_loss\")\n    plt.plot(epochs, test_loss, label=\"test_loss\")\n    plt.title(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n    plt.title(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n\n    plt.savefig(\"loss_curves.png\",bbox_inches='tight') \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curves of our model\nplot_loss_curves(model_0_results)\nwandb.log({\"Media/Loss_Curves\": wandb.Image(\"loss_curves.png\")})","metadata":{"id":"7r4UYmdrdDPk","outputId":"be3d1bd6-6888-4445-abe0-4a7549804e42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CALCULATE PFBETA","metadata":{}},{"cell_type":"code","source":"#class_name_int,pred_label_int\n\nlabels = class_name_int\npredictions = pred_label_int\nbeta = 1\npfbeta_val = pfbeta(labels, predictions, beta)\nconfig.pfbeta=pfbeta_val\nprint(pfbeta_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms_text = wandb_run_name + \" Is Complete \" \n#send_sms(\"+16479807463\",sms_text,AWS_ACCESS_KEY,AWS_SECRET_KEY,region_name)\n\n# Mark the run as finished\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
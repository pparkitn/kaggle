{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dsptlp/spark?scriptVersionId=163361867\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e862926a","metadata":{"papermill":{"duration":0.00543,"end_time":"2024-02-19T00:52:00.893872","exception":false,"start_time":"2024-02-19T00:52:00.888442","status":"completed"},"tags":[]},"source":["# SPARK \n","- Reasons to Use Spark\n","- This notebook will compare Spark VS Pandas\n","\n","# NOTE \n","- Spark is designed to work in a distributed computing environment and is most effective when dealing with large datasets and clusters of machines. \n","- In Kaggle's limited environment, we are not using a distributed computing environment but will be able to use all the computer resources which will be the only benefit. \n","\n","# SPARK ADVANTAGES\n","\n","1. **Speed:** Spark is known for its speed, as it can perform in-memory processing, reducing the need to write intermediate results to disk. This makes Spark well-suited for iterative algorithms and interactive data analysis.\n","\n","2. **Ease of Use:** Spark provides high-level APIs in languages such as Scala, Java, Python, and R, making it accessible to a wide range of users. It also offers built-in libraries for various tasks like SQL, machine learning (MLlib), graph processing (GraphX), and stream processing (Spark Streaming).\n","\n","3. **Scalability:** Spark is designed for distributed computing, allowing it to scale horizontally across a cluster of machines. This makes it suitable for handling large datasets and processing tasks that would be challenging for single-node systems.\n","\n","4. **Versatility:** Spark supports a variety of data processing scenarios, including batch processing, interactive queries, streaming analytics, and machine learning. This versatility makes it a preferred choice for organizations with diverse data analysis needs.\n","\n","5. **Fault Tolerance:** Spark provides fault tolerance through lineage information and resilient distributed datasets (RDDs). If a node fails, Spark can recompute the lost data using the lineage information, ensuring the reliability of data processing.\n","\n","6. **Integration with Big Data Ecosystem:** Spark seamlessly integrates with other big data tools and technologies, such as Hadoop Distributed File System (HDFS), Apache Hive, Apache HBase, and more. This allows users to leverage existing data storage and processing systems.\n","\n","7. **Community Support:** Spark has a large and active open-source community. This means continuous development, improvements, and a wealth of resources, including documentation, forums, and tutorials.\n","\n","8. **In-Memory Processing:** Spark's ability to store intermediate data in memory rather than writing to disk can significantly improve performance, especially for iterative algorithms and interactive data analysis, compared to traditional disk-based processing.\n"]},{"cell_type":"code","execution_count":1,"id":"f6f64c43","metadata":{"execution":{"iopub.execute_input":"2024-02-19T00:52:00.906498Z","iopub.status.busy":"2024-02-19T00:52:00.905912Z","iopub.status.idle":"2024-02-19T00:52:56.857278Z","shell.execute_reply":"2024-02-19T00:52:56.855215Z"},"papermill":{"duration":55.96415,"end_time":"2024-02-19T00:52:56.863308","exception":false,"start_time":"2024-02-19T00:52:00.899158","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["pyspark not found. Installing...\n","pyspark installed successfully!\n"]}],"source":["# Install PySpark\n","try:\n","    import pyspark\n","except ImportError:\n","    print(\"pyspark not found. Installing...\")\n","    !pip install pyspark > pyspark.log.txt\n","    print(\"pyspark installed successfully!\")"]},{"cell_type":"code","execution_count":2,"id":"889216f5","metadata":{"execution":{"iopub.execute_input":"2024-02-19T00:52:56.876363Z","iopub.status.busy":"2024-02-19T00:52:56.875853Z","iopub.status.idle":"2024-02-19T00:53:00.104942Z","shell.execute_reply":"2024-02-19T00:53:00.103294Z"},"papermill":{"duration":3.239454,"end_time":"2024-02-19T00:53:00.10804","exception":false,"start_time":"2024-02-19T00:52:56.868586","status":"completed"},"tags":[]},"outputs":[],"source":["# Import necessary libraries\n","from pyspark.sql import SparkSession\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.preprocessing import StandardScaler\n","from matplotlib.lines import Line2D\n","from matplotlib import cm\n","import numpy as np \n","import pandas as pd\n","import seaborn as sns\n","import warnings\n","import timeit\n","\n","# Suppress all warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"id":"01f72cc0","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-19T00:53:00.121727Z","iopub.status.busy":"2024-02-19T00:53:00.120941Z","iopub.status.idle":"2024-02-19T00:53:06.262549Z","shell.execute_reply":"2024-02-19T00:53:06.261155Z"},"papermill":{"duration":6.151765,"end_time":"2024-02-19T00:53:06.265286","exception":false,"start_time":"2024-02-19T00:53:00.113521","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/02/19 00:53:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["# Create a Spark session\n","spark = SparkSession.builder.appName(\"Spark\").getOrCreate()"]},{"cell_type":"code","execution_count":4,"id":"b0094856","metadata":{"execution":{"iopub.execute_input":"2024-02-19T00:53:06.281394Z","iopub.status.busy":"2024-02-19T00:53:06.2803Z","iopub.status.idle":"2024-02-19T00:53:06.286872Z","shell.execute_reply":"2024-02-19T00:53:06.285556Z"},"papermill":{"duration":0.017559,"end_time":"2024-02-19T00:53:06.289479","exception":false,"start_time":"2024-02-19T00:53:06.27192","status":"completed"},"tags":[]},"outputs":[],"source":["file_path  = \"/kaggle/input/tabular-dataset-ready-for-malicious-url-detection/train_dataset.csv\""]},{"cell_type":"code","execution_count":5,"id":"1b7257c0","metadata":{"execution":{"iopub.execute_input":"2024-02-19T00:53:06.30331Z","iopub.status.busy":"2024-02-19T00:53:06.302771Z","iopub.status.idle":"2024-02-19T01:04:08.648968Z","shell.execute_reply":"2024-02-19T01:04:08.647379Z"},"papermill":{"duration":662.356278,"end_time":"2024-02-19T01:04:08.651895","exception":false,"start_time":"2024-02-19T00:53:06.295617","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 47:====================================================>   (14 + 1) / 15]\r"]},{"name":"stdout","output_type":"stream","text":["Execution time using SPARK: 662.332919824 seconds\n","CPU times: user 495 ms, sys: 153 ms, total: 648 ms\n","Wall time: 11min 2s\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["%%time\n","\n","def load_csv_using_spark():\n","    df = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","    # Perform the summary: count number of records grouped by a column\n","    summary_df = df.groupBy(\"label\").count()\n","    \n","    # Perform an action (triggers execution, note that spark uses Lazy Execution)\n","    summary_df.collect() #show()\n","    \n","# Measure the execution time\n","execution_time = timeit.timeit(load_csv_using_spark, number=10)\n","\n","# Print the result\n","print(f\"Execution time using SPARK: {execution_time} seconds\")"]},{"cell_type":"code","execution_count":6,"id":"98dd074f","metadata":{"execution":{"iopub.execute_input":"2024-02-19T01:04:08.698413Z","iopub.status.busy":"2024-02-19T01:04:08.697566Z","iopub.status.idle":"2024-02-19T01:13:47.248796Z","shell.execute_reply":"2024-02-19T01:13:47.244901Z"},"papermill":{"duration":578.610487,"end_time":"2024-02-19T01:13:47.285184","exception":false,"start_time":"2024-02-19T01:04:08.674697","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution time using PANDAS: 578.5252357930001 seconds\n","CPU times: user 8min 46s, sys: 50.1 s, total: 9min 36s\n","Wall time: 9min 38s\n"]}],"source":["%%time\n","\n","def load_csv_using_pandas():\n","    data_df = pd.read_csv(file_path, delimiter=',') \n","    summary_df = data_df[['url_has_login','label']].groupby(['label']).count()\n","    \n","# Measure the execution time\n","execution_time = timeit.timeit(load_csv_using_pandas, number=10)\n","\n","# Print the result\n","print(f\"Execution time using PANDAS: {execution_time} seconds\")"]},{"cell_type":"code","execution_count":null,"id":"f5156b33","metadata":{"papermill":{"duration":0.023795,"end_time":"2024-02-19T01:13:47.3299","exception":false,"start_time":"2024-02-19T01:13:47.306105","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cb2695e5","metadata":{"papermill":{"duration":0.020149,"end_time":"2024-02-19T01:13:47.370436","exception":false,"start_time":"2024-02-19T01:13:47.350287","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"55476b47","metadata":{"papermill":{"duration":0.020503,"end_time":"2024-02-19T01:13:47.412386","exception":false,"start_time":"2024-02-19T01:13:47.391883","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"20899b55","metadata":{"papermill":{"duration":0.020352,"end_time":"2024-02-19T01:13:47.453138","exception":false,"start_time":"2024-02-19T01:13:47.432786","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0fe2774d","metadata":{"papermill":{"duration":0.020521,"end_time":"2024-02-19T01:13:47.494294","exception":false,"start_time":"2024-02-19T01:13:47.473773","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"08e78862","metadata":{"papermill":{"duration":0.019943,"end_time":"2024-02-19T01:13:47.534574","exception":false,"start_time":"2024-02-19T01:13:47.514631","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7f887e04","metadata":{"papermill":{"duration":0.020223,"end_time":"2024-02-19T01:13:47.575437","exception":false,"start_time":"2024-02-19T01:13:47.555214","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4441201,"sourceId":7624364,"sourceType":"datasetVersion"},{"datasetId":2529204,"sourceId":4295427,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1312.815594,"end_time":"2024-02-19T01:13:50.433794","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-19T00:51:57.6182","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}